{
 "PRed":[
  {
   "PR":{
    "__lazy_json__":"pr_json/199599499.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Noarch",
    "migrator_version":0
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/204618495.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"4.6.1"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/207825788.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"4.6.2"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/207831142.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"4.6.3"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/219872649.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"CompilerRebuild",
    "migrator_version":1,
    "name":"Python 3.7, GCC 7, R 3.5.1, openBLAS 0.3.2"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/241589127.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"4.7.0"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/242531732.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"4.7.1"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/257648826.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"ArchRebuild",
    "migrator_version":1,
    "name":"aarch64 and ppc64le addition"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/299563795.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"4.8.0"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  }
 ],
 "bad":{
  "code":404,
  "exception":"HTTP Error 404: Not Found",
  "traceback":[
   "Traceback (most recent call last):",
   "  File \"/root/repo/cf-scripts/conda_forge_tick/auto_tick.xsh\", line 678, in main",
   "    hash_type=attrs.get('hash_type', 'sha256'))",
   "  File \"/root/repo/cf-scripts/conda_forge_tick/auto_tick.xsh\", line 98, in run",
   "    migrate_return = migrator.migrate(recipe_dir, attrs, **kwargs)",
   "  File \"/root/repo/cf-scripts/conda_forge_tick/migrators.xsh\", line 393, in migrate",
   "    new_patterns = self.get_hash_patterns('meta.yaml', urls, hash_type)",
   "  File \"/root/repo/cf-scripts/conda_forge_tick/migrators.xsh\", line 323, in get_hash_patterns",
   "    hash = hash_url(url, hash_type)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/site-packages/rever/tools.xsh\", line 207, in hash_url",
   "    for b in stream_url_progress(url, verb='Hashing', quiet=quiet):",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/site-packages/rever/tools.xsh\", line 179, in stream_url_progress",
   "    with urllib.request.urlopen(url) as f:",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 222, in urlopen",
   "    return opener.open(url, data, timeout)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 531, in open",
   "    response = meth(req, response)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 641, in http_response",
   "    'http', request, response, code, msg, hdrs)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 563, in error",
   "    result = self._call_chain(*args)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 503, in _call_chain",
   "    result = func(*args)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 755, in http_error_302",
   "    return self.parent.open(new, timeout=req.timeout)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 531, in open",
   "    response = meth(req, response)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 641, in http_response",
   "    'http', request, response, code, msg, hdrs)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 563, in error",
   "    result = self._call_chain(*args)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 503, in _call_chain",
   "    result = func(*args)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 755, in http_error_302",
   "    return self.parent.open(new, timeout=req.timeout)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 531, in open",
   "    response = meth(req, response)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 641, in http_response",
   "    'http', request, response, code, msg, hdrs)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 569, in error",
   "    return self._call_chain(*args)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 503, in _call_chain",
   "    result = func(*args)",
   "  File \"/opt/conda/envs/run_env/lib/python3.7/urllib/request.py\", line 649, in http_error_default",
   "    raise HTTPError(req.full_url, code, msg, hdrs, fp)",
   "urllib.error.HTTPError: HTTP Error 404: Not Found",
   ""
  ],
  "url":"https://files.pythonhosted.org/packages/source/b/beautifulsoup4/beautifulsoup4-4.8.1.tar.gz"
 },
 "conda-forge.yml":{
  "compiler_stack":"comp7",
  "max_py_ver":"37",
  "max_r_ver":"35",
  "provider":{
   "linux_aarch64":"azure",
   "linux_ppc64le":"azure",
   "win":"azure"
  }
 },
 "feedstock_name":"beautifulsoup4",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "description":"Beautiful Soup is a library for pulling data out of HTML and XML files.\nIt provides ways of navigating, searching, and modifying parse trees.\n",
   "dev_url":"https://code.launchpad.net/beautifulsoup",
   "doc_source_url":"https://github.com/newvem/beautifulsoup4/blob/master/doc/source/index.rst",
   "doc_url":"http://beautiful-soup-4.readthedocs.io/en/latest/",
   "home":"http://www.crummy.com/software/BeautifulSoup/",
   "license":"MIT",
   "license_family":"MIT",
   "license_file":"COPYING.txt",
   "summary":"Python library designed for screen-scraping"
  },
  "build":{
   "number":"0",
   "script":" -m pip install . --no-deps -vv"
  },
  "extra":{
   "recipe-maintainers":[
    "jschueller",
    "nehaljwani",
    "jschueller",
    "nehaljwani",
    "jschueller",
    "nehaljwani"
   ]
  },
  "package":{
   "name":"beautifulsoup4",
   "version":"4.8.0"
  },
  "requirements":{
   "host":[
    "python",
    "pip",
    "python",
    "pip",
    "python",
    "pip"
   ],
   "run":[
    "python",
    "soupsieve >=1.2",
    "python",
    "soupsieve >=1.2",
    "python",
    "soupsieve >=1.2"
   ]
  },
  "source":{
   "sha256":"25288c9e176f354bf277c0a10aa96c782a6a18a17122dba2e8cec4a97e03343b",
   "url":"https://pypi.io/packages/source/b/beautifulsoup4/beautifulsoup4-4.8.0.tar.gz"
  },
  "test":{
   "imports":[
    "bs4",
    "bs4",
    "bs4"
   ]
  }
 },
 "name":"beautifulsoup4",
 "new_version":"4.8.1",
 "pinning_version":"2019.07.19",
 "raw_meta_yaml":"{% set version = \"4.8.0\" %}\n\npackage:\n  name: beautifulsoup4\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/b/beautifulsoup4/beautifulsoup4-{{ version }}.tar.gz\n  sha256: 25288c9e176f354bf277c0a10aa96c782a6a18a17122dba2e8cec4a97e03343b\n\nbuild:\n  # Uses 2to3 and cannot be noarch.\n  number: 0\n  script: \"{{ PYTHON }} -m pip install . --no-deps -vv\"\n\nrequirements:\n  host:\n    - python\n    - pip\n  run:\n    - python\n    - soupsieve >=1.2\n\ntest:\n  imports:\n    - bs4\n\nabout:\n  home: http://www.crummy.com/software/BeautifulSoup/\n  license: MIT\n  license_family: MIT\n  license_file: COPYING.txt\n  summary: Python library designed for screen-scraping\n  description: |\n    Beautiful Soup is a library for pulling data out of HTML and XML files.\n    It provides ways of navigating, searching, and modifying parse trees.\n  doc_url: http://beautiful-soup-4.readthedocs.io/en/latest/\n  doc_source_url: https://github.com/newvem/beautifulsoup4/blob/master/doc/source/index.rst\n  dev_url: https://code.launchpad.net/beautifulsoup\n\nextra:\n  recipe-maintainers:\n    - jschueller\n    - nehaljwani\n",
 "req":{
  "__set__":true,
  "elements":[
   "pip",
   "python",
   "soupsieve"
  ]
 },
 "smithy_version":"3.4.1",
 "url":"https://pypi.io/packages/source/b/beautifulsoup4/beautifulsoup4-4.8.0.tar.gz",
 "version":"4.8.0"
}