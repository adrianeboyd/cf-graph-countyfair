{
 "PRed":[
  {
   "PR":{
    "__lazy_json__":"pr_json/217488370.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"CompilerRebuild",
    "migrator_version":1,
    "name":"Python 3.7, GCC 7, R 3.5.1, openBLAS 0.3.2"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  }
 ],
 "bad":false,
 "conda-forge.yml":{
  "compiler_stack":"comp7",
  "max_py_ver":"37",
  "max_r_ver":"35"
 },
 "feedstock_name":"jieba3k",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "description":"Jieba (Chinese for 'to stutter') Chinese text segmentation: built to be the best Python Chinese word segmentation module.",
   "dev_url":"https://github.com/fxsjy/jieba/tree/jieba3k",
   "home":"https://github.com/fxsjy/jieba/tree/jieba3k",
   "license":"MIT",
   "license_family":"MIT",
   "license_file":"/LICENSE",
   "summary":"Chinese Words Segementation Utilities"
  },
  "build":{
   "number":"1001",
   "script":" -m pip install . --no-deps --ignore-installed --no-cache-dir -vvv"
  },
  "extra":{
   "recipe-maintainers":[
    "ganeshhubale",
    "synapticarbors",
    "ganeshhubale",
    "synapticarbors",
    "ganeshhubale",
    "synapticarbors"
   ]
  },
  "package":{
   "name":"jieba3k",
   "version":"0.35.1"
  },
  "requirements":{
   "host":[
    "python",
    "pip",
    "python",
    "pip",
    "python",
    "pip"
   ],
   "run":[
    "python",
    "python",
    "python"
   ]
  },
  "source":{
   "fn":"jieba3k-0.35.1.zip",
   "sha256":"980a4f2636b778d312518066be90c7697d410dd5a472385f5afced71a2db1c10",
   "url":"https://pypi.io/packages/source/j/jieba3k/jieba3k-0.35.1.zip"
  },
  "test":{
   "imports":[
    "jieba",
    "jieba",
    "jieba"
   ]
  }
 },
 "name":"jieba3k",
 "new_version":"0.35.1",
 "pinning_version":"2018.09.20",
 "raw_meta_yaml":"{% set name = \"jieba3k\" %}\n{% set version = \"0.35.1\" %}\n{% set file_ext = \"zip\" %}\n{% set hash_type = \"sha256\" %}\n{% set hash_value = \"980a4f2636b778d312518066be90c7697d410dd5a472385f5afced71a2db1c10\" %}\n\npackage:\n  name: '{{ name|lower }}'\n  version: '{{ version }}'\n\nsource:\n  fn: '{{ name }}-{{ version }}.{{ file_ext }}'\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.{{ file_ext }}\n  '{{ hash_type }}': '{{ hash_value }}'\n\nbuild:\n  number: 1001\n  script: \"{{ PYTHON }} -m pip install . --no-deps --ignore-installed --no-cache-dir -vvv\"\n  skip: True  # [py2k]\n\nrequirements:\n  host:\n    - python\n    - pip\n  run:\n    - python\n\ntest:\n  imports:\n    - jieba\n\nabout:\n  home: https://github.com/fxsjy/jieba/tree/jieba3k\n  license: MIT\n  license_family: MIT\n  # See issue https://github.com/fxsjy/jieba/issues/545 for adding LICENSE to src distribution\n  license_file: '{{ environ[\"RECIPE_DIR\"] }}/LICENSE'\n  summary: Chinese Words Segementation Utilities\n  description: \"Jieba (Chinese for 'to stutter') Chinese text segmentation: built to be the best Python Chinese word segmentation module.\"\n  dev_url: 'https://github.com/fxsjy/jieba/tree/jieba3k'\n\nextra:\n  recipe-maintainers: \n  - ganeshhubale\n  - synapticarbors\n",
 "req":{
  "__set__":true,
  "elements":[
   "pip",
   "python"
  ]
 },
 "smithy_version":"3.1.12",
 "time":1568070554.240316,
 "url":"https://pypi.io/packages/source/j/jieba3k/jieba3k-0.35.1.zip",
 "version":"0.35.1"
}