{
 "bad":{
  "exception":"<class 'requests.exceptions.ReadTimeout'>: A connection-level exception occurred: HTTPSConnectionPool(host='api.github.com', port=443): Read timed out. (read timeout=10)",
  "traceback":[
   "Traceback (most recent call last):",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 421, in _make_request",
   "    six.raise_from(e, None)",
   "  File \"<string>\", line 3, in raise_from",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 416, in _make_request",
   "    httplib_response = conn.getresponse()",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/http/client.py\", line 1322, in getresponse",
   "    response.begin()",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/http/client.py\", line 303, in begin",
   "    version, status, reason = self._read_status()",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/http/client.py\", line 264, in _read_status",
   "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/socket.py\", line 669, in readinto",
   "    return self._sock.recv_into(b)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/urllib3/contrib/pyopenssl.py\", line 326, in recv_into",
   "    raise timeout(\"The read operation timed out\")",
   "socket.timeout: The read operation timed out",
   "",
   "During handling of the above exception, another exception occurred:",
   "",
   "Traceback (most recent call last):",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send",
   "    resp = conn.urlopen(",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 719, in urlopen",
   "    retries = retries.increment(",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/urllib3/util/retry.py\", line 400, in increment",
   "    raise six.reraise(type(error), error, _stacktrace)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/urllib3/packages/six.py\", line 735, in reraise",
   "    raise value",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 665, in urlopen",
   "    httplib_response = self._make_request(",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 423, in _make_request",
   "    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 330, in _raise_timeout",
   "    raise ReadTimeoutError(",
   "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.github.com', port=443): Read timed out. (read timeout=10)",
   "",
   "During handling of the above exception, another exception occurred:",
   "",
   "Traceback (most recent call last):",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/github3/models.py\", line 196, in _request",
   "    return request_method(*args, **kwargs)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/requests/sessions.py\", line 546, in get",
   "    return self.request('GET', url, **kwargs)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/github3/session.py\", line 169, in request",
   "    response = super(GitHubSession, self).request(*args, **kwargs)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/requests/sessions.py\", line 533, in request",
   "    resp = self.send(prep, **send_kwargs)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/requests/sessions.py\", line 646, in send",
   "    r = adapter.send(request, **kwargs)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/requests/adapters.py\", line 529, in send",
   "    raise ReadTimeout(e, request=request)",
   "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='api.github.com', port=443): Read timed out. (read timeout=10)",
   "",
   "During handling of the above exception, another exception occurred:",
   "",
   "Traceback (most recent call last):",
   "  File \"/root/repo/cf-scripts/conda_forge_tick/auto_tick.py\", line 659, in main",
   "    migrator_uid, pr_json = run(",
   "  File \"/root/repo/cf-scripts/conda_forge_tick/auto_tick.py\", line 120, in run",
   "    feedstock_dir, repo = get_repo(",
   "  File \"/root/repo/cf-scripts/conda_forge_tick/git_utils.py\", line 119, in get_repo",
   "    fork_repo = gh.repository(ctx.github_username, feedstock_reponame)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/github3/github.py\", line 1981, in repository",
   "    json = self._json(self._get(url), 200)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/github3/models.py\", line 211, in _get",
   "    return self._request(\"get\", url, **kwargs)",
   "  File \"/opt/conda/envs/run_env/lib/python3.8/site-packages/github3/models.py\", line 201, in _request",
   "    raise exceptions.ConnectionError(exc)",
   "github3.exceptions.ConnectionError: <class 'requests.exceptions.ReadTimeout'>: A connection-level exception occurred: HTTPSConnectionPool(host='api.github.com', port=443): Read timed out. (read timeout=10)",
   ""
  ]
 },
 "conda-forge.yml":{},
 "feedstock_name":"nccl",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "description":"The NVIDIA Collective Communications Library (NCCL) implements multi-GPU\nand multi-node collective communication primitives that are performance\noptimized for NVIDIA GPUs. NCCL provides routines such as all-gather,\nall-reduce, broadcast, reduce, reduce-scatter, that are optimized to\nachieve high bandwidth over PCIe and NVLink high-speed interconnect.\n",
   "dev_url":"https://github.com/NVIDIA/nccl",
   "doc_url":"https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html",
   "home":"https://developer.nvidia.com/nccl",
   "license":"BSD-3-Clause",
   "license_family":"BSD",
   "license_file":"LICENSE.txt",
   "summary":"Optimized primitives for collective multi-GPU communication"
  },
  "build":{
   "number":"0",
   "run_exports":[
    "subpackage_stub",
    "subpackage_stub",
    "subpackage_stub"
   ],
   "skip":true
  },
  "extra":{
   "recipe-maintainers":[
    "jakirkham",
    "jakirkham",
    "jakirkham"
   ]
  },
  "package":{
   "name":"nccl",
   "version":"2.5.6.1"
  },
  "requirements":{
   "build":[
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "cuda_compiler_stub",
    "make"
   ]
  },
  "source":{
   "sha256":"38a37d98be11f43232b988719226866b407f08b9666dcaf345796bd8f354ef54",
   "url":"https://github.com/NVIDIA/nccl/archive/v2.5.6-1.tar.gz"
  },
  "test":{
   "commands":[
    "test -f \"${PREFIX}/include/nccl.h\"",
    "test -f \"${PREFIX}/lib/libnccl.so\"",
    "test -f \"${PREFIX}/lib/libnccl_static.a\"",
    "test -f \"${PREFIX}/include/nccl.h\"",
    "test -f \"${PREFIX}/lib/libnccl.so\"",
    "test -f \"${PREFIX}/lib/libnccl_static.a\"",
    "test -f \"${PREFIX}/include/nccl.h\"",
    "test -f \"${PREFIX}/lib/libnccl.so\"",
    "test -f \"${PREFIX}/lib/libnccl_static.a\""
   ]
  }
 },
 "name":"nccl",
 "new_version":"2.5.6-2",
 "raw_meta_yaml":"{% set name = \"nccl\" %}\n{% set version = \"2.5.6\" %}\n{% set revision = \"1\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}.{{ revision }}\n\nsource:\n  url: https://github.com/NVIDIA/nccl/archive/v{{ version }}-{{ revision }}.tar.gz\n  sha256: 38a37d98be11f43232b988719226866b407f08b9666dcaf345796bd8f354ef54\n\nbuild:\n  number: 0\n  skip: true  # [(not linux64) or (cuda_compiler_version == \"None\")]\n  run_exports:\n    # xref: https://github.com/NVIDIA/nccl/issues/218\n    - {{ pin_subpackage(name, max_pin=\"x\") }}\n\nrequirements:\n  build:\n    - {{ compiler(\"c\") }}\n    - {{ compiler(\"cxx\") }}\n    - {{ compiler(\"cuda\") }}\n    - make\n\ntest:\n  commands:\n    - test -f \"${PREFIX}/include/nccl.h\"\n    - test -f \"${PREFIX}/lib/libnccl.so\"\n    - test -f \"${PREFIX}/lib/libnccl_static.a\"\n\nabout:\n  home: https://developer.nvidia.com/nccl\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file: LICENSE.txt\n  summary: Optimized primitives for collective multi-GPU communication\n\n  description: |\n    The NVIDIA Collective Communications Library (NCCL) implements multi-GPU\n    and multi-node collective communication primitives that are performance\n    optimized for NVIDIA GPUs. NCCL provides routines such as all-gather,\n    all-reduce, broadcast, reduce, reduce-scatter, that are optimized to\n    achieve high bandwidth over PCIe and NVLink high-speed interconnect.\n\n  doc_url: https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html\n  dev_url: https://github.com/NVIDIA/nccl\n\nextra:\n  recipe-maintainers:\n    - jakirkham\n",
 "req":{
  "__set__":true,
  "elements":[
   "c_compiler_stub",
   "cuda_compiler_stub",
   "cxx_compiler_stub",
   "make"
  ]
 },
 "url":"https://github.com/NVIDIA/nccl/archive/v2.4.6-1.tar.gz",
 "version":"2.5.6.1"
}