{
 "bad":"Upstream: Error getting upstream version",
 "conda-forge.yml":{},
 "feedstock_name":"nvidia-apex",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "dev_url":"https://github.com/NVIDIA/apex",
   "doc_url":"https://nvidia.github.io/apex/",
   "home":"https://nvidia.github.io/apex/",
   "license":"BSD-3-Clause",
   "license_family":"BSD",
   "license_file":"LICENSE",
   "summary":"a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training."
  },
  "build":{
   "number":"0",
   "script":" -m pip install . -vv ",
   "skip":true
  },
  "extra":{
   "recipe-maintainers":[
    "oblute",
    "benhuff",
    "oblute",
    "benhuff",
    "oblute",
    "benhuff"
   ]
  },
  "package":{
   "name":"nvidia-apex",
   "version":"0.1"
  },
  "requirements":{
   "build":[
    "c_compiler_stub",
    "cxx_compiler_stub",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "c_compiler_stub",
    "cxx_compiler_stub"
   ],
   "host":[
    "python",
    "pytorch",
    "setuptools",
    "pip",
    "python",
    "pytorch",
    "setuptools",
    "pip",
    "python",
    "pytorch",
    "setuptools",
    "pip"
   ],
   "run":[
    "python",
    "pytorch",
    "tqdm",
    "numpy",
    "PyYAML",
    "pytest",
    "python",
    "pytorch",
    "tqdm",
    "numpy",
    "PyYAML",
    "pytest",
    "python",
    "pytorch",
    "cxxfilt",
    "tqdm",
    "numpy",
    "PyYAML",
    "pytest"
   ]
  },
  "source":{
   "sha256":"cc5ce27aa30b5ade54d520fafc1cd7d293dfba58c51851759a034d03e3f370bb",
   "url":"https://github.com/NVIDIA/apex/archive/088985936518be7e25795a30d8ab33affa9db6ed.tar.gz"
  },
  "test":{
   "imports":[
    "apex",
    "apex.amp",
    "apex.parallel",
    "apex.optimizers",
    "apex.normalization.fused_layer_norm",
    "apex",
    "apex.amp",
    "apex.parallel",
    "apex.optimizers",
    "apex.normalization.fused_layer_norm",
    "apex",
    "apex.amp",
    "apex.parallel",
    "apex.optimizers",
    "apex.normalization.fused_layer_norm"
   ]
  }
 },
 "name":"nvidia-apex",
 "raw_meta_yaml":"{% set name = \"nvidia-apex\" %}\n{% set version = \"0.1\" %}\n{% set commit = \"088985936518be7e25795a30d8ab33affa9db6ed\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://github.com/NVIDIA/apex/archive/{{ commit }}.tar.gz\n  sha256: cc5ce27aa30b5ade54d520fafc1cd7d293dfba58c51851759a034d03e3f370bb\n\nbuild:\n  number: 0\n  script: \"{{ PYTHON }} -m pip install . -vv \"\n  skip: True  # [osx or (not py36) or (win and vc<14)]\n\nrequirements:\n  build:\n    - {{ compiler('c') }}\n    - {{ compiler('cxx') }}\n  host:\n    - python\n    - pytorch\n    - setuptools\n    - pip\n  run:\n    - python\n    - pytorch\n    - cxxfilt  # [linux]\n    - tqdm\n    - numpy\n    - PyYAML\n    - pytest\n\ntest:\n  imports:\n    - apex\n    - apex.amp\n    - apex.parallel\n    - apex.optimizers\n    - apex.normalization.fused_layer_norm\n\nabout:\n  home: \"https://nvidia.github.io/apex/\"\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file: LICENSE\n  summary: \"a Pytorch extension with NVIDIA-maintained utilities to streamline mixed precision and distributed training.\"\n  doc_url: \"https://nvidia.github.io/apex/\"\n  dev_url: \"https://github.com/NVIDIA/apex\"\n\nextra:\n  recipe-maintainers:\n    - oblute\n    - benhuff\n",
 "req":{
  "__set__":true,
  "elements":[
   "c_compiler_stub",
   "cxx_compiler_stub",
   "cxxfilt",
   "numpy",
   "pip",
   "pytest",
   "python",
   "pytorch",
   "pyyaml",
   "setuptools",
   "tqdm"
  ]
 },
 "url":"https://github.com/NVIDIA/apex/archive/088985936518be7e25795a30d8ab33affa9db6ed.tar.gz",
 "version":"0.1"
}