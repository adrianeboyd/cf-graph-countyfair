{
 "bad":false,
 "conda-forge.yml":{},
 "feedstock_name":"segtok",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "dev_url":"https://github.com/fnl/segtok",
   "doc_url":"http://fnl.es/segtok-a-segmentation-and-tokenization-library.html",
   "home":"https://github.com/fnl/segtok",
   "license":"MIT",
   "license_family":"MIT",
   "license_file":"LICENSE",
   "summary":"sentence segmentation and word tokenization tools"
  },
  "build":{
   "entry_points":[
    "tokenizer = segtok.tokenizer:main",
    "segmenter = segtok.segmenter:main",
    "tokenizer = segtok.tokenizer:main",
    "segmenter = segtok.segmenter:main",
    "tokenizer = segtok.tokenizer:main",
    "segmenter = segtok.segmenter:main"
   ],
   "noarch":"python",
   "number":"0",
   "script":"-m pip install . -vv"
  },
  "extra":{
   "recipe-maintainers":[
    "oblute",
    "rluria14",
    "ndmaxar",
    "oblute",
    "rluria14",
    "ndmaxar",
    "oblute",
    "rluria14",
    "ndmaxar"
   ]
  },
  "package":{
   "name":"segtok",
   "version":"1.5.7"
  },
  "requirements":{
   "host":[
    "pip",
    "python",
    "pip",
    "python",
    "pip",
    "python"
   ],
   "run":[
    "python",
    "regex",
    "python",
    "regex",
    "python",
    "regex"
   ]
  },
  "source":{
   "sha256":"e9ccb989648877e29c6e59782148e8fc6731ca3027dc9f05a48769a24bc0f328",
   "url":"https://pypi.io/packages/source/s/segtok/segtok-1.5.7.tar.gz"
  },
  "test":{
   "commands":[
    "tokenizer --help",
    "segmenter --help",
    "tokenizer --help",
    "segmenter --help",
    "tokenizer --help",
    "segmenter --help"
   ],
   "imports":[
    "segtok",
    "segtok",
    "segtok"
   ]
  }
 },
 "name":"segtok",
 "new_version":"1.5.7",
 "raw_meta_yaml":"{% set name = \"segtok\" %}\n{% set version = \"1.5.7\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: e9ccb989648877e29c6e59782148e8fc6731ca3027dc9f05a48769a24bc0f328\n\nbuild:\n  noarch: python\n  number: 0\n  entry_points:\n    - tokenizer = segtok.tokenizer:main\n    - segmenter = segtok.segmenter:main\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - python\n  run:\n    - python\n    - regex\n\ntest:\n  imports:\n    - segtok\n  commands:\n    - tokenizer --help\n    - segmenter --help\n\nabout:\n  home: https://github.com/fnl/segtok\n  license: MIT\n  license_family: MIT\n  # License isn't packaged, track issue here: https://github.com/fnl/segtok/issues/22\n  license_file: LICENSE\n  summary: \"sentence segmentation and word tokenization tools\"\n  doc_url: http://fnl.es/segtok-a-segmentation-and-tokenization-library.html\n  dev_url: https://github.com/fnl/segtok\n\nextra:\n  recipe-maintainers:\n    - oblute\n    - rluria14\n    - ndmaxar\n",
 "req":{
  "__set__":true,
  "elements":[
   "pip",
   "python",
   "regex"
  ]
 },
 "requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "python",
    "regex"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "strong_exports":false,
 "total_requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "python",
    "regex"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "url":"https://pypi.io/packages/source/s/segtok/segtok-1.5.7.tar.gz",
 "version":"1.5.7"
}